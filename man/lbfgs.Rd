% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimize.R
\name{lbfgs}
\alias{lbfgs}
\title{L-BFGS optimizer (limited memory BFGS)}
\usage{
lbfgs(
  objective_fn,
  params,
  m = 10,
  max_iter = 1000,
  tol = 1e-06,
  maximize = FALSE,
  verbose = 0
)
}
\arguments{
\item{objective_fn}{Function taking list of value parameters, returns scalar}

\item{params}{List of value objects (initial parameter values)}

\item{m}{Number of correction pairs to store, default 10}

\item{max_iter}{Maximum iterations, default 1000}

\item{tol}{Convergence tolerance on gradient norm, default 1e-6}

\item{maximize}{If TRUE, maximize; if FALSE (default), minimize}

\item{verbose}{Print progress every N iterations (0 for silent)}
}
\value{
A list containing:
\item{params}{List of value objects at optimum}
\item{value}{Objective function value at optimum}
\item{gradient}{Gradient at optimum}
\item{iterations}{Number of iterations performed}
\item{converged}{TRUE if gradient norm < tol}
}
\description{
Memory-efficient variant of BFGS that stores only the last m
correction pairs instead of the full inverse Hessian approximation.
Suitable for large-scale optimization.
}
\details{
L-BFGS uses the two-loop recursion algorithm to compute the search
direction without explicitly forming the inverse Hessian. Memory
usage is O(m*n) instead of O(n^2) for full BFGS.
}
